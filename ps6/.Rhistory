Rg <- 1.11 #RR for genentic factor alone (mean of MS 110 ORs)
Re <- 1 #RR for env factor alone
Ri <- mde #(rnorm(100)) #case-only interaction ratio magnitude
m1 <- (1-g)*(1-e)
m2 <- g*(1-e)*Rg
m3 <- (1-g)*e*Re
m4 <- (g*e*Rg*Re*Ri)
Va <- (m1+m2+m3+m4)*(1/m1+1/m2+1/m3+1/m4)
n <- ((Zalpha + Zbeta)^2 * Va) / (log(Ri))^2
return(c(power = beta, sampleSize = n, RR = Ri))
}
powerCalc1 <- t(mapply(bonf = 200, gPrev = seq(0.1, 0.5, 0.1), mde = 1.5,
FUN = powerCalcFun))
powerCalc1
powerCalcFun <- function(bonf, gPrev, mde) {
alpha <- 0.20/bonf #bonf
Zalpha <- qnorm(1-alpha/2)
beta <- 0.8
Zbeta <- qnorm(beta)
g <- gPrev #seq(0,0.5,length.out=1000) #prev of genentic factor
e <- 0.5 #prev of env factor
Rg <- 1.11 #RR for genentic factor alone (mean of MS 110 ORs)
Re <- 1 #RR for env factor alone
Ri <- mde #(rnorm(100)) #case-only interaction ratio magnitude
m1 <- (1-g)*(1-e)
m2 <- g*(1-e)*Rg
m3 <- (1-g)*e*Re
m4 <- (g*e*Rg*Re*Ri)
Va <- (m1+m2+m3+m4)*(1/m1+1/m2+1/m3+1/m4)
n <- ((Zalpha + Zbeta)^2 * Va) / (log(Ri))^2
return(c(gPrev, sampleSize = n, RR = Ri))
}
powerCalc1 <- t(mapply(bonf = 200, gPrev = seq(0.1, 0.5, 0.1), mde = 1.5,
FUN = powerCalcFun))
powerCalc1
powerCalc_MS <- t(mapply(bonf = 200, gPrev = seq(0.1, 0.5, 0.1), mde = 1.5,
FUN = powerCalcFun))
powerCalc_RA <- t(mapply(bonf = 101, gPrev = seq(0.1, 0.5, 0.1), mde = 1.5,
FUN = powerCalcFun))
powerCalc_SLE <- t(mapply(bonf = 51, gPrev = seq(0.1, 0.5, 0.1), mde = 1.5,
FUN = powerCalcFun))
powerCalc_MS
powerCalc_MS <- t(mapply(disease = "MS",
bonf = 200, gPrev = seq(0.1, 0.5, 0.1), mde = 1.5,
FUN = powerCalcFun))
powerCalc_RA <- t(mapply(disease = "RA",
bonf = 101, gPrev = seq(0.1, 0.5, 0.1), mde = 1.5,
FUN = powerCalcFun))
powerCalc_SLE <- t(mapply(disease = "SLE",
bonf = 51, gPrev = seq(0.1, 0.5, 0.1), mde = 1.5,
FUN = powerCalcFun))
powerCalcFun <- function(disease, bonf, gPrev, mde) {
alpha <- 0.20/bonf #bonf
Zalpha <- qnorm(1-alpha/2)
beta <- 0.8
Zbeta <- qnorm(beta)
g <- gPrev #seq(0,0.5,length.out=1000) #prev of genentic factor
e <- 0.5 #prev of env factor
Rg <- 1.11 #RR for genentic factor alone (mean of MS 110 ORs)
Re <- 1 #RR for env factor alone
Ri <- mde #(rnorm(100)) #case-only interaction ratio magnitude
m1 <- (1-g)*(1-e)
m2 <- g*(1-e)*Rg
m3 <- (1-g)*e*Re
m4 <- (g*e*Rg*Re*Ri)
Va <- (m1+m2+m3+m4)*(1/m1+1/m2+1/m3+1/m4)
n <- ((Zalpha + Zbeta)^2 * Va) / (log(Ri))^2
return(c(disease = disease, gPrev, sampleSize = n, RR = Ri))
}
powerCalc_MS <- t(mapply(disease = "MS",
bonf = 200, gPrev = seq(0.1, 0.5, 0.1), mde = 1.5,
FUN = powerCalcFun))
powerCalc_RA <- t(mapply(disease = "RA",
bonf = 101, gPrev = seq(0.1, 0.5, 0.1), mde = 1.5,
FUN = powerCalcFun))
powerCalc_SLE <- t(mapply(disease = "SLE",
bonf = 51, gPrev = seq(0.1, 0.5, 0.1), mde = 1.5,
FUN = powerCalcFun))
powerCalc_ALL <- rbind(powerCalc_MS, powerCalc_RA, powerCalc_SLE)
write.csv(powerCalc_ALL, "~/Google Drive/F31/powerCalc_10312017.csv",
row.names = F, quote = F)
powerCalcFun <- function(disease, bonf, gPrev, mde) {
alpha <- 0.20/bonf #bonf
Zalpha <- qnorm(1-alpha/2)
beta <- 0.8
Zbeta <- qnorm(beta)
g <- gPrev #seq(0,0.5,length.out=1000) #prev of genentic factor
e <- 0.4 #prev of env factor
Rg <- 1.11 #RR for genentic factor alone (mean of MS 110 ORs)
Re <- 1 #RR for env factor alone
Ri <- mde #(rnorm(100)) #case-only interaction ratio magnitude
m1 <- (1-g)*(1-e)
m2 <- g*(1-e)*Rg
m3 <- (1-g)*e*Re
m4 <- (g*e*Rg*Re*Ri)
Va <- (m1+m2+m3+m4)*(1/m1+1/m2+1/m3+1/m4)
n <- ((Zalpha + Zbeta)^2 * Va) / (log(Ri))^2
return(c(disease = disease, gPrev, sampleSize = n, RR = Ri))
}
powerCalc_MS <- t(mapply(disease = "MS",
bonf = 200, gPrev = seq(0.1, 0.5, 0.1), mde = 1.5,
FUN = powerCalcFun))
powerCalc_RA <- t(mapply(disease = "RA",
bonf = 101, gPrev = seq(0.1, 0.5, 0.1), mde = 1.5,
FUN = powerCalcFun))
powerCalc_SLE <- t(mapply(disease = "SLE",
bonf = 51, gPrev = seq(0.1, 0.5, 0.1), mde = 1.5,
FUN = powerCalcFun))
powerCalc_MS
for (i in 1:5) {
alpha <- 0.2# 0.2/110 #bonf
Zalpha <- qnorm(1-alpha/2)
beta <- 0.8
Zbeta <- qnorm(beta)
g <- gPrev[i] #seq(0,0.5,length.out=1000) #prev of genentic factor
e <- 0.4 #prev of env factor
Rg <- 1.11 #RR for genentic factor alone (mean of MS 110 ORs)
Re <- 1 #RR for env factor alone
Ri <- abs(rnorm(1000)) #case-only interaction ratio magnitude
m1 <- (1-g)*(1-e)
m2 <- g*(1-e)*Rg
m3 <- (1-g)*e*Re
m4 <- (g*e*Rg*Re*Ri)
Va <- (m1+m2+m3+m4)*(1/m1+1/m2+1/m3+1/m4)
n <- ((Zalpha + Zbeta)^2 * Va) / (log(Ri))^2
power[[i]] <- data.frame(sampleSize = n, RR = Ri)
power[[i]] <- power[[i]][power[[i]]$sampleSize <=5000,]
power[[i]] <- power[[i]][order(power[[i]]$RR),]
}
power
powerCalc_MS <- t(mapply(disease = "MS",
bonf = 1, gPrev = seq(0.1, 0.5, 0.1), mde = 1.5,
FUN = powerCalcFun))
powerCalc_RA <- t(mapply(disease = "RA",
bonf = 1, gPrev = seq(0.1, 0.5, 0.1), mde = 1.5,
FUN = powerCalcFun))
powerCalc_SLE <- t(mapply(disease = "SLE",
bonf = 1, gPrev = seq(0.1, 0.5, 0.1), mde = 1.5,
FUN = powerCalcFun))
powerCalc_ALL <- rbind(powerCalc_MS, powerCalc_RA, powerCalc_SLE)
powerCalc_ALL
write.csv(powerCalc_ALL, "~/Google Drive/F31/powerCalc_10312017.csv",
row.names = F, quote = F)
write.csv(powerCalc_ALL, "~/Google Drive/F31/powerCalc_10312017.csv",
row.names = F, quote = F)
\documentclass{article}
\title{Problem Set 6}
\author{Cameron Adams}
\usepackage{float, hyperref}
\usepackage[margin = 1in]{geometry}
\usepackage{graphicx}
\usepackage{sectsty}
\usepackage{hyperref}
\usepackage{amsmath}
\begin{document}
%\SweaveOpts{concordance=TRUE}
\maketitle
<<echo = F>>=
rm(list = ls())
#set working dir
setwd("/Users/CamAdams/repos/STAT243/ps6/")
#load packages
require(RCurl)
require(stringr)
require(pryr)
require(microbenchmark)
#set gobal chunk options
knitr::opts_chunk$set(cache=F,
background='#F7F7F7',
results='markup')
@
%Q1
\section{For this question you will read a journal article ...}
\subsection{What are the goals of their simulation study and what are the metrics that they consider in assessing their method?}
The goal of the simulation is to investiagte the finite sample properties of the proposed test. They are using simulated power and significance levels to assess method performance given different mixture proportions, D, etc.
\subsection{What choices did the authors have to make in designing their simulation study? What are the key aspects of the data generating mechanism that likely affect the statistical power of the test? Are there data-generating scenarios that the authors did not consider that would be useful to consider?}
Mixture proportions, D (differenc means between guassian distributions), norminal $\alpha$, and sample size. ?
\subsection{Do their tables do a good job of presenting the simulation results and do you have any alternative suggestions for how to do this?}
\subsection{Interpret their tables on power (Tables 2 and 4) - do the results make sense in terms of how the power varies as a function of the data generating mechanism?}
\subsection{How do you think the authors decided to use 1000 simulations. Would 10 simulations be enough? How might we decide if 1000 simulations is enough?}
\section{Using the Stack Overflow database (http://www.stat.berkeley.edu/share/paciorek/stackoverflow-2016.db), write SQL code that will determine which users have asked only R-related questions and no Pythonrelated questions. Those of you with more experience with SQL might do this in a single query, but it’s perfectly fine to create one or more views and then use those views to get the result as a subsequent query. Report how many unique such users there are based on running your query from either R or Python. The Stack Overflow SQLite database is ~ 650 MB on disk, which should be manageable on most of your laptops, but if you run into problems, you can use an SCF machine or Savio (in the latter case you’ll need to install the RSQLite package).}
%1
<<prob2>>=
rm(list = ls())
library(RSQLite)
###############
# load SQL database
#set SQL db driver
drv <- dbDriver("SQLite")
#connec to db
dir <- "/Users/CamAdams/repos/STAT243/ps6/" # path to where the .db file is
dbFilename <- 'stackoverflow-2016.db'
db <- dbConnect(drv, dbname = file.path(dir, dbFilename))
#########
# write SQL code that will determine
# which users have asked only R-related questions and no Python related questions
# simple query to get 5 rows from a table
#dbGetQuery(db, "select * from questions limit 5")
dbListTables(db)
dbListFields(db, "users")
dbListFields(db, "questions")
dbListFields(db, "questions_tags")
dbListFields(db, "answers")
dbListFields(db, "questionsAugment")
dbGetQuery(db, "select python from questions_tag limit 5")
dbGetQuery(db, "select * from users limit 5")
dbGetQuery(db, "select * from questions limit 5")
dbGetQuery(db, "select * from answers limit 5")
dbGetQuery(db, "select * from questions_tags limit 5")
dbGetQuery(db, "select * from questionsAugment limit 5")
#three way join between questions, questions_tags, and questionsAugment on
#question id
results <- dbGetQuery(db, "SELECT DISTINCT displayname from questions,
questions_tags, questionsAugment
WHERE questions.questionid = questions_tags.questionid
AND questionsAugment.questionid = questions.questionid
AND tag != 'python' AND tag = 'r'")
dim(results)
dbGetQuery(db, "select * from questions_tags limit 5")
\documentclass{article}
\title{Problem Set 6}
\author{Cameron Adams}
\usepackage{float, hyperref}
\usepackage[margin = 1in]{geometry}
\usepackage{graphicx}
\usepackage{sectsty}
\usepackage{hyperref}
\usepackage{amsmath}
\begin{document}
%\SweaveOpts{concordance=TRUE}
\maketitle
<<echo = F>>=
rm(list = ls())
#set working dir
setwd("/Users/CamAdams/repos/STAT243/ps6/")
#load packages
require(RCurl)
require(stringr)
require(pryr)
require(microbenchmark)
#set gobal chunk options
knitr::opts_chunk$set(cache=F,
background='#F7F7F7',
results='markup')
@
%Q1
\section{For this question you will read a journal article ...}
\subsection{What are the goals of their simulation study and what are the metrics that they consider in assessing their method?}
The goal of the simulation is to investiagte the finite sample properties of the proposed test. They are using simulated power and significance levels to assess method performance given different mixture proportions, D, etc.
\subsection{What choices did the authors have to make in designing their simulation study? What are the key aspects of the data generating mechanism that likely affect the statistical power of the test? Are there data-generating scenarios that the authors did not consider that would be useful to consider?}
Mixture proportions, D (differenc means between guassian distributions), norminal $\alpha$, and sample size. ?
\subsection{Do their tables do a good job of presenting the simulation results and do you have any alternative suggestions for how to do this?}
\subsection{Interpret their tables on power (Tables 2 and 4) - do the results make sense in terms of how the power varies as a function of the data generating mechanism?}
\subsection{How do you think the authors decided to use 1000 simulations. Would 10 simulations be enough? How might we decide if 1000 simulations is enough?}
\section{Using the Stack Overflow database (http://www.stat.berkeley.edu/share/paciorek/stackoverflow-2016.db), write SQL code that will determine which users have asked only R-related questions and no Pythonrelated questions. Those of you with more experience with SQL might do this in a single query, but it’s perfectly fine to create one or more views and then use those views to get the result as a subsequent query. Report how many unique such users there are based on running your query from either R or Python. The Stack Overflow SQLite database is ~ 650 MB on disk, which should be manageable on most of your laptops, but if you run into problems, you can use an SCF machine or Savio (in the latter case you’ll need to install the RSQLite package).}
%1
<<prob2>>=
rm(list = ls())
library(RSQLite)
###############
# load SQL database
#set SQL db driver
drv <- dbDriver("SQLite")
#connec to db
dir <- "/Users/CamAdams/repos/STAT243/ps6/" # path to where the .db file is
dbFilename <- 'stackoverflow-2016.db'
db <- dbConnect(drv, dbname = file.path(dir, dbFilename))
#########
# write SQL code that will determine
# which users have asked only R-related questions and no Python related questions
# simple query to get 5 rows from a table
#dbGetQuery(db, "select * from questions limit 5")
dbListTables(db)
dbListFields(db, "users")
dbListFields(db, "questions")
dbListFields(db, "questions_tags")
dbListFields(db, "answers")
dbListFields(db, "questionsAugment")
dbGetQuery(db, "select python from questions_tag limit 5")
dbGetQuery(db, "select * from users limit 5")
dbGetQuery(db, "select * from questions limit 5")
dbGetQuery(db, "select * from answers limit 5")
dbGetQuery(db, "select * from questions_tags limit 5")
dbGetQuery(db, "select * from questionsAugment limit 5")
#three way join between questions, questions_tags, and questionsAugment on
#question idg
dbSendQuery(db, 'create view users_tagR as * from questions_tags
WHERE tag = "python"')
dbSendQuery(db, 'create view users_tagR as * from questions_tags
WHERE tag = "python"')
dbSendQuery(db, 'CREATE VIEW users_tagR AS SELECT * FROM questions_tags
WHERE tag = "python"')
dbSendQuery(db, "CREATE VIEW users_tagR AS SELECT * FROM questions_tags
WHERE tag = 'python'")
\documentclass{article}
\title{Problem Set 6}
\author{Cameron Adams}
\usepackage{float, hyperref}
\usepackage[margin = 1in]{geometry}
\usepackage{graphicx}
\usepackage{sectsty}
\usepackage{hyperref}
\usepackage{amsmath}
\begin{document}
%\SweaveOpts{concordance=TRUE}
\maketitle
<<echo = F>>=
rm(list = ls())
#set working dir
setwd("/Users/CamAdams/repos/STAT243/ps6/")
#load packages
require(RCurl)
require(stringr)
require(pryr)
require(microbenchmark)
#set gobal chunk options
knitr::opts_chunk$set(cache=F,
background='#F7F7F7',
results='markup')
@
%Q1
\section{For this question you will read a journal article ...}
\subsection{What are the goals of their simulation study and what are the metrics that they consider in assessing their method?}
The goal of the simulation is to investiagte the finite sample properties of the proposed test. They are using simulated power and significance levels to assess method performance given different mixture proportions, D, etc.
\subsection{What choices did the authors have to make in designing their simulation study? What are the key aspects of the data generating mechanism that likely affect the statistical power of the test? Are there data-generating scenarios that the authors did not consider that would be useful to consider?}
Mixture proportions, D (differenc means between guassian distributions), norminal $\alpha$, and sample size. ?
\subsection{Do their tables do a good job of presenting the simulation results and do you have any alternative suggestions for how to do this?}
\subsection{Interpret their tables on power (Tables 2 and 4) - do the results make sense in terms of how the power varies as a function of the data generating mechanism?}
\subsection{How do you think the authors decided to use 1000 simulations. Would 10 simulations be enough? How might we decide if 1000 simulations is enough?}
\section{Using the Stack Overflow database (http://www.stat.berkeley.edu/share/paciorek/stackoverflow-2016.db), write SQL code that will determine which users have asked only R-related questions and no Pythonrelated questions. Those of you with more experience with SQL might do this in a single query, but it’s perfectly fine to create one or more views and then use those views to get the result as a subsequent query. Report how many unique such users there are based on running your query from either R or Python. The Stack Overflow SQLite database is ~ 650 MB on disk, which should be manageable on most of your laptops, but if you run into problems, you can use an SCF machine or Savio (in the latter case you’ll need to install the RSQLite package).}
%1
<<prob2>>=
rm(list = ls())
library(RSQLite)
###############
# load SQL database
#set SQL db driver
drv <- dbDriver("SQLite")
#connec to db
dir <- "/Users/CamAdams/repos/STAT243/ps6/" # path to where the .db file is
dbFilename <- 'stackoverflow-2016.db'
db <- dbConnect(drv, dbname = file.path(dir, dbFilename))
#########
# write SQL code that will determine
# which users have asked only R-related questions and no Python related questions
# simple query to get 5 rows from a table
#dbGetQuery(db, "select * from questions limit 5")
dbListTables(db)
dbListFields(db, "users")
dbListFields(db, "questions")
dbListFields(db, "questions_tags")
dbListFields(db, "answers")
dbListFields(db, "questionsAugment")
dbGetQuery(db, "select python from questions_tag limit 5")
dbGetQuery(db, "select * from users limit 5")
dbGetQuery(db, "select * from questions limit 5")
dbGetQuery(db, "select * from answers limit 5")
dbGetQuery(db, "select * from questions_tags limit 5")
dbGetQuery(db, "select * from questionsAugment limit 5")
#three way join between questions, questions_tags, and questionsAugment on
#question idg
dbSendQuery(db, "CREATE VIEW users_tagR AS SELECT * FROM questions_tags
WHERE tag = 'python'")
dbDisconnect()
dbDisconnect(db)
\documentclass{article}
\title{Problem Set 6}
\author{Cameron Adams}
\usepackage{float, hyperref}
\usepackage[margin = 1in]{geometry}
\usepackage{graphicx}
\usepackage{sectsty}
\usepackage{hyperref}
\usepackage{amsmath}
\begin{document}
%\SweaveOpts{concordance=TRUE}
\maketitle
<<echo = F>>=
rm(list = ls())
#set working dir
setwd("/Users/CamAdams/repos/STAT243/ps6/")
#load packages
require(RCurl)
require(stringr)
require(pryr)
require(microbenchmark)
#set gobal chunk options
knitr::opts_chunk$set(cache=F,
background='#F7F7F7',
results='markup')
@
%Q1
\section{For this question you will read a journal article ...}
\subsection{What are the goals of their simulation study and what are the metrics that they consider in assessing their method?}
The goal of the simulation is to investiagte the finite sample properties of the proposed test. They are using simulated power and significance levels to assess method performance given different mixture proportions, D, etc.
\subsection{What choices did the authors have to make in designing their simulation study? What are the key aspects of the data generating mechanism that likely affect the statistical power of the test? Are there data-generating scenarios that the authors did not consider that would be useful to consider?}
Mixture proportions, D (differenc means between guassian distributions), norminal $\alpha$, and sample size. ?
\subsection{Do their tables do a good job of presenting the simulation results and do you have any alternative suggestions for how to do this?}
\subsection{Interpret their tables on power (Tables 2 and 4) - do the results make sense in terms of how the power varies as a function of the data generating mechanism?}
\subsection{How do you think the authors decided to use 1000 simulations. Would 10 simulations be enough? How might we decide if 1000 simulations is enough?}
\section{Using the Stack Overflow database (http://www.stat.berkeley.edu/share/paciorek/stackoverflow-2016.db), write SQL code that will determine which users have asked only R-related questions and no Pythonrelated questions. Those of you with more experience with SQL might do this in a single query, but it’s perfectly fine to create one or more views and then use those views to get the result as a subsequent query. Report how many unique such users there are based on running your query from either R or Python. The Stack Overflow SQLite database is ~ 650 MB on disk, which should be manageable on most of your laptops, but if you run into problems, you can use an SCF machine or Savio (in the latter case you’ll need to install the RSQLite package).}
%1
<<prob2>>=
rm(list = ls())
library(RSQLite)
###############
# load SQL database
#set SQL db driver
drv <- dbDriver("SQLite")
#connec to db
dir <- "/Users/CamAdams/repos/STAT243/ps6/" # path to where the .db file is
dbFilename <- 'stackoverflow-2016.db'
db <- dbConnect(drv, dbname = file.path(dir, dbFilename))
#########
# write SQL code that will determine
# which users have asked only R-related questions and no Python related questions
# simple query to get 5 rows from a table
#dbGetQuery(db, "select * from questions limit 5")
dbListTables(db)
dbListFields(db, "users")
dbListFields(db, "questions")
dbListFields(db, "questions_tags")
dbListFields(db, "answers")
dbListFields(db, "questionsAugment")
dbGetQuery(db, "select python from questions_tag limit 5")
dbGetQuery(db, "select * from users limit 5")
dbGetQuery(db, "select * from questions limit 5")
dbGetQuery(db, "select * from answers limit 5")
dbGetQuery(db, "select * from questions_tags limit 5")
dbGetQuery(db, "select * from questionsAugment limit 5")
#three way join between questions, questions_tags, and questionsAugment on
#question idg
dbSendQuery(db, "CREATE VIEW users_tagR AS SELECT * FROM questions_tags
WHERE questions_tags.tag = 'python'")
dbSendQuery(db, "CREATE VIEW tarR AS SELECT * FROM questions_tags
WHERE questions_tags.tag = 'python'")
dbListTables(db)
dbDisconnect(db)
\documentclass{article}
\title{Problem Set 6}
\author{Cameron Adams}
\usepackage{float, hyperref}
\usepackage[margin = 1in]{geometry}
\usepackage{graphicx}
\usepackage{sectsty}
\usepackage{hyperref}
\usepackage{amsmath}
\begin{document}
%\SweaveOpts{concordance=TRUE}
\maketitle
<<echo = F>>=
rm(list = ls())
#set working dir
setwd("/Users/CamAdams/repos/STAT243/ps6/")
#load packages
require(RCurl)
require(stringr)
require(pryr)
require(microbenchmark)
#set gobal chunk options
knitr::opts_chunk$set(cache=F,
background='#F7F7F7',
results='markup')
@
%Q1
\section{For this question you will read a journal article ...}
\subsection{What are the goals of their simulation study and what are the metrics that they consider in assessing their method?}
The goal of the simulation is to investiagte the finite sample properties of the proposed test. They are using simulated power and significance levels to assess method performance given different mixture proportions, D, etc.
\subsection{What choices did the authors have to make in designing their simulation study? What are the key aspects of the data generating mechanism that likely affect the statistical power of the test? Are there data-generating scenarios that the authors did not consider that would be useful to consider?}
Mixture proportions, D (differenc means between guassian distributions), norminal $\alpha$, and sample size. ?
\subsection{Do their tables do a good job of presenting the simulation results and do you have any alternative suggestions for how to do this?}
\subsection{Interpret their tables on power (Tables 2 and 4) - do the results make sense in terms of how the power varies as a function of the data generating mechanism?}
\subsection{How do you think the authors decided to use 1000 simulations. Would 10 simulations be enough? How might we decide if 1000 simulations is enough?}
\section{Using the Stack Overflow database (http://www.stat.berkeley.edu/share/paciorek/stackoverflow-2016.db), write SQL code that will determine which users have asked only R-related questions and no Pythonrelated questions. Those of you with more experience with SQL might do this in a single query, but it’s perfectly fine to create one or more views and then use those views to get the result as a subsequent query. Report how many unique such users there are based on running your query from either R or Python. The Stack Overflow SQLite database is ~ 650 MB on disk, which should be manageable on most of your laptops, but if you run into problems, you can use an SCF machine or Savio (in the latter case you’ll need to install the RSQLite package).}
%1
<<prob2>>=
rm(list = ls())
library(RSQLite)
###############
# load SQL database
#set SQL db driver
drv <- dbDriver("SQLite")
#connec to db
dir <- "/Users/CamAdams/repos/STAT243/ps6/" # path to where the .db file is
dbFilename <- 'stackoverflow-2016.db'
db <- dbConnect(drv, dbname = file.path(dir, dbFilename))
#########
# write SQL code that will determine
# which users have asked only R-related questions and no Python related questions
# simple query to get 5 rows from a table
#dbGetQuery(db, "select * from questions limit 5")
dbListTables(db)
dbListFields(db, "users")
dbListFields(db, "questions")
dbListFields(db, "questions_tags")
dbListFields(db, "answers")
dbListFields(db, "questionsAugment")
dbGetQuery(db, "select python from questions_tag limit 5")
dbGetQuery(db, "select * from users limit 5")
dbGetQuery(db, "select * from questions limit 5")
dbGetQuery(db, "select * from answers limit 5")
dbGetQuery(db, "select * from questions_tags limit 5")
dbGetQuery(db, "select * from questionsAugment limit 5")
#three way join between questions, questions_tags, and questionsAugment on
#question idg
dbSendQuery(db, "CREATE VIEW tag_python AS SELECT * FROM questions_tags
WHERE questions_tags.tag = 'python'")
dbSendQuery(db, "CREATE VIEW tag_r AS SELECT * FROM questions_tags
WHERE questions_tags.tag = 'r'")
dbGetQuery(db, "select * from questions_tags limit 5")
dbGetQuery(db, "select * from questionsAugment limit 5")
dbGetQuery(db, "select * from questions limit 5")
