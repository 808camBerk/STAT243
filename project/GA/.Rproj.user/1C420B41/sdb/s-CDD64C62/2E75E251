{
    "collab_server" : "",
    "contents" : "---\ntitle: \"Kaggle/Facebook-K-Nearest Neighbors Testing\"\nauthor: \"Cam Adams\"\ndate: \"November 22, 2016\"\noutput: html_document\n---\n\nI tested FNN:knn prediction on the training set. I partioned the training dataset into geographic grids and then ran prediction on those grids. This implementation ran on the first 10 grids.\n\n```{r,message=F,warning=F}\n###############\n## Chunk 1: housekeeping\n###############\n\nrm(list=ls()) \nt1 <- Sys.time()\n\nsetwd(\"/Users/CamAdams/Google Drive/240C/finalProject/Facebook-Checkin-Predicton/\")\n\nrequire(data.table,quietly = T)\nrequire(bit64,quietly = T)\nrequire(scales,quietly = T)\nrequire(ggplot2,quietly = T)\nrequire(RColorBrewer,quietly = T)\nrequire(plotly,quietly = T)\nrequire(dplyr,quietly = T) \nrequire(plyr,quietly = T)\nrequire(tidyr,quietly = T)\nrequire(cluster,quietly = T)\nrequire(fastcluster,quietly = T)\nrequire(limma,quietly = T)\nrequire(class,quietly = T)\nrequire(FNN,quietly = T)\nrequire(kknn,quietly = T)\nrequire(parallel,quietly = T)\nrequire(fields,quietly = T)\nrequire(knitr,quietly = T)\n\nSet1 <- brewer.pal(9,\"Set1\") #pretty colors\nset.seed(84)\n```\n\n\n```{r}\n###############\n## Chunk2 2: Training Data Prep\n###############\n\n#read in training data\ntrain_all <- fread(\"/Users/CamAdams/Google Drive/240C/finalProject/train.csv\",\n                   integer64='character',drop=c(1),showProgress=F)\n#create test set\ntest_df <- filter(train_all, time > max(time)*.9)\n\n#create train set\ntrain_df <- filter(train_all, time <= max(time)*.9)\n#train_df %>% dplyr::count(place_id) %>% filter(n>59) -> place_id.subset.train #find place_id n<60\n#train_df <- train_df[train_df$place_id %in% place_id.subset.train$place_id,] #subset for place_id >=60\n\nrm(train_all)\n```\n\n\n```{r}\n  #grid size: 400 grids\n  xGrid <- 10*4 #40\n  yGrid <- 10*4 #40\n  #grid sequence\n  xCell <- seq(10/xGrid,10,by=10/xGrid) \n  yCell <- seq(10/yGrid,10,by=10/yGrid)\n  #coordinates\n  yCor <- matrix(c(rep(yCell,xGrid)),ncol=1)\n  xCor <- matrix(sapply(xCell,function(x) (c(rep(x,yGrid)))),ncol=1)\n```\n\n\n```{r}\n#############\n## Chunk 4: functions for KNN\n#############  \n  \n# KNN matrix fucntion\nknnWeights <- function(df) {\n  cbind(\n    norm.func(df$x)*5, #weight x \n    norm.func(df$y),    \n    norm.func(df$hour),\n    norm.func(df$min),\n    norm.func(df$time),\n    norm.func(df$accuracy))\n}\n\n#normalizization function\nnorm.func <- function(x) {\n  normed <- (x - min(x)) / (max(x) - min(x))\n  return(normed) }\n\n# KNN funciton for prediction \n  knn.grid <- function(a,b,k) {   \n    \n  #  a <- kTest[100,1]\n  #  b <- kTest[100,2]\n  #  k <- kTest[100,3]\n    # subset train and test grids\n    tmp.test_df <- data.frame(test_df[test_df$x < a & test_df$x > (a-10/xGrid) &\n                   test_df$y < b & test_df$y > (b-10/yGrid),])\n  \n    tmp.train_df <- data.frame(train_df[train_df$x < a & train_df$x > (a-10/xGrid) &\n                    train_df$y < b & train_df$y > (b-10/yGrid),])\n    \n    # Create time variables\n    tmp.train_df$hour <-  (tmp.train_df$time/60) %% 24 #24 hrs day\n    tmp.train_df$min  <- (tmp.train_df$time/60) %% 24 %% 60\n    \n    tmp.test_df$hour <-  (tmp.test_df$time/60) %% 24 #24 hrs day\n    tmp.test_df$min  <- (tmp.test_df$time/60) %% 24 %% 60\n\n    # get train and test labels\n    train_df_labels <- tmp.train_df$place_id\n    test_df_labels <- tmp.test_df$place_id\n    \n    # apply weights to test and training sets\n    train_df_knn <- knnWeights(tmp.train_df)\n    test_df_knn <- knnWeights(tmp.test_df)\n    \n    ## KNN ##\n    pred <- FNN::knn(train = train_df_knn,test = test_df_knn,cl=train_df_labels,k=k,prob=F)\n\n      ## process knn results ##\n      index <- attributes(pred)$nn.index #get nearest neighbor index\n      knn.index <- sapply(seq(1:ncol(index)),function(x) train_df_labels[index[,x]]) #apply place_id to nn.index positions\n  \n      #get top 3 predictions by nearest neighbor frequency    \n        # mean of 6.64 sec\n        knn.indexT <- t(knn.index)\n        top3 <- sapply((1:nrow(knn.index)),\n                     function(x) names(sort(table(knn.indexT[,x]),decreasing=T)[1:3]),\n                     simplify = \"array\")\n    \n    results <- cbind(t(top3),as.character(pred),test_df_labels)\n    return(results)\n  }\n\n```\n\n```{r}\n#############\n## Chunk 5: KNN prediction\n#############  \n  \n#test for cluster sizes\n  #optimize on 5% of 0.25 x 0.25 grids randomly sampled\ngridSamp <- sample(seq(1,length(xCor)),1600*0.05,replace=F)\nkSizes <- seq(1,99,6)\n\nkTest <- expand.grid(xCor[sample(seq(1,1600),ceiling(1600*0.005))],\n                     yCor[sample(seq(1,1600),ceiling(1600*0.005))],\n                     kSizes)\n\npreds <- mcmapply(knn.grid,a=kTest[1:10,1],b=kTest[1:10,2],k=kTest[1:10,3],\n                  SIMPLIFY = F,\n                  mc.preschedule = F,\n                  mc.cores = getOption(\"mc.cores\", 4L))\n\n#process results and get accuracy:\npred.func <- function(x) {\n  tmp <- data.frame(one=ifelse(x[,1] == x[,5],1,0),\n                    two=ifelse(x[,2] == x[,5],1/2,0),\n                    three=ifelse(x[,3] == x[,5],1/3,0))\n  mean(rowSums(tmp,na.rm=T))\n}\nzz <- sapply(preds,pred.func) \n\nplot(kTest[1:10,3],zz)\nabline(h=mean(zz))\n\n\n  #overall mean accuracy\n  mean(unlist(top3.accuracy))\n  \n  #mean accuracy per grid  \n  grid.means <- unlist(lapply(top3.accuracy,function(x) mean(x)))\n  grid.means\n  \n   #grid plot\n    p1 <- data.frame(x1=xCor[c(1:10)],y1=yCor[c(1:10)],grid.means)\n    p1$x2 <- p1[,1]-10/xGrid\n    p1$y2 <- p1[,2]-10/yGrid\n    p1$grid.means.Norm <- norm.func(p1$grid.means)\n    \n    p1\n  \n    par(mar=c(5,4,4,1),xpd=T,oma=c(0,0,0,0))\n    plot(x=p1$x1,y=p1$y1,xlim=c(0,12),ylim=c(0,10),col=\"white\",xlab=\"X\",ylab=\"Y\",\n        # bty=\"n\",xaxt=\"n\",yaxt=\"n\",\n         main=\"KNN grids prediction accuracy\")\n    rect(p1[,1],p1[,2],p1[,4],p1[,5],col=alpha(\"red\",p1[,3]),border=NA)\n    colorbar.plot(x=11,y=3,col=(colorRampPalette(c(\"white\",\"red\")))(10),\n                  strip=seq(0,1,.1),horizontal=F,strip.width=.05,strip.length = .25)\n    text(x=11,y=4.2,\"More\\naccuracy\",cex=.75)\n    text(x=11,y=2.3,\"Less\\naccuracy\",cex=.75)\n\n\n  #plot grid means \n  par(mar=c(5,4,4,1),xpd=F,oma=c(0,0,0,0))\n  plot(grid.means,type=\"l\",lwd=3,col=Set1[1],ylim=c(0,1))\n  lines(sapply(preds,function(x) mean(x[,4] == x[,5])),type=\"l\",lwd=3,col=Set1[2])\n  abline(h=0.5,lwd=1,lty=2)\n\n#timing.\nt2 <- Sys.time()\t\nt2-t1 #Time for entire script\n\n```\n\n\nunused code\n```{r,eval=F,echo=F}\n#############\n## Chunk 6: unused code\n#############  \n\n  # KNN funciton for prediction \n  knn.grid <- function(a,b) {   \n    \n    #a <- xCor[10]\n    #b <- yCor[10]\n    \n    # subset train and test grids\n    tmp.train_df <- data.frame(train_df[train_df$x < a & train_df$x > (a-10/xGrid) &\n                    train_df$y < b & train_df$y > (b-10/yGrid),])\n   \n    tmp.test_df <- data.frame(test_df[test_df$x < a & test_df$x > (a-10/xGrid) &\n                   test_df$y < b & test_df$y > (b-10/yGrid),])\n    \n    # kmeans clustering for centroids for use as additional features\n    cl <- stats::kmeans(tmp.train_df[1:2],centers=length(unique(tmp.train_df$place_id)),iter.max=10,nstart=1)\n    cl.fit <- data.frame(x_kmean=fitted(cl,method=\"centers\")[,1],y_kmean=fitted(cl,method=\"centers\")[,2])\n    tmp.train_df <- bind_cols(tmp.train_df,cl.fit)\n    \n    cl <- stats::kmeans(tmp.test_df[1:2],centers=length(unique(tmp.train_df$place_id)),iter.max=10,nstart=1)\n    cl.fit <- data.frame(x_kmean=fitted(cl,method=\"centers\")[,1],y_kmean=fitted(cl,method=\"centers\")[,2])\n    tmp.test_df <- bind_cols(tmp.test_df,cl.fit)\n    \n    # plot clusters and kmeans centroids\n        #  cl <- clara(tmp.train_df[1:2],k=131,samples=10,sampsize=500)\n        #  plot(tmp.train_df$x,tmp.train_df$y,\n        #       col=alpha(rep(Set1,10)[factor(tmp.train_df$place_id)],alpha=norm.func(tmp.train_df$accuracy)),pch=20)\n        #  points(cl$data[cl$i.med,])\n\n    # Create time variables\n    tmp.train_df$hour <-  (tmp.train_df$time/60) %% 24 #24 hrs day\n    tmp.train_df$weekday <- (tmp.train_df$time/(60*24)) %% 7 #days/week\n    tmp.train_df$month <- (tmp.train_df$time/(60*24*30)) %% 12 #months\n    tmp.train_df$year <- tmp.train_df$time/(60*24*365)\n    tmp.train_df$day <- tmp.train_df$time/(60*24) %% 365 #365 days/yr\n    \n    tmp.test_df$hour <-  (tmp.test_df$time/60) %% 24 #24 hrs day\n    tmp.test_df$weekday <- (tmp.test_df$time/(60*24)) %% 7 #days/week\n    tmp.test_df$month <- (tmp.test_df$time/(60*24*30)) %% 12 #months\n    tmp.test_df$year <- tmp.test_df$time/(60*24*365)\n    tmp.test_df$day <- tmp.test_df$time/(60*24) %% 365 #365 days/yr\n      \n    \n    # get train and test labels\n    train_df_labels <- tmp.train_df$place_id\n    test_df_labels <- tmp.test_df$place_id\n    \n    # weighting function\n    wknnWeights <- function(df) {\n          cbind(\n            norm.func(df$x),  \n            norm.func(df$y*3),    \n            norm.func(df$x_kmean),\n            norm.func(df$y_kmean),\n    #       norm.func(df$x_median),\n    #       norm.func(df$y_median),\n            norm.func(df$hour),\n            norm.func(df$weekday),\n            norm.func(df$month),\n            norm.func(df$accuracy))\n      }\n    \n    # apply weights to test and training sets\n    train_df_wknn <- wknnWeights(tmp.train_df)\n    test_df_wknn <- wknnWeights(tmp.test_df)\n    \n    # KNN \n    pred <- FNN::knn(train = train_df_wknn, test = test_df_wknn,cl=train_df_labels, k=15,prob = T)\n    \n     #weighted KNN (very slow)\n#    pred3 <- kknn(formula=as.factor(place_id) ~ .,\n#                  train=data.frame(train_df_wknn,place_id=train_df_labels), test=data.frame(test_df_wknn),\n#                  distance = 1,kernel = \"triangular\")\n#    })\n    \n    \n#   mean(pred == test_df_labels)\n#   mean(pred3$fitted.values == test_df_labels)\n\n    ## process knn results ##\n    knn.place_id <- train_df_labels\n    \n    index <- attributes(pred)$nn.index\n    knn.index <- sapply(seq(1:ncol(index)),function(x) knn.place_id[index[,x]])\n    results <- apply(knn.index,1,function(x) paste(names(sort(table(x),decreasing=T)[1:3]),collapse=\" \"))\n\n    #  index_w <- pred3$C\n    #  wknn.index <- sapply(seq(1:ncol(index_w)),function(x) knn.place_id[index_w[,x]])\n    #  results_w <- apply(knn.index,1,function(x) paste(names(sort(table(x),decreasing=T)[1:3]),collapse=\" \"))\n   \n    results <- cbind(results,as.character(pred),test_df_labels)\n    #  results_w <- cbind(results_w,pred3$fitted.values,test_df_labels)\n    \n   # resList <- list(results)#,results_w)\n    return(results)\n}\n\nsystem.time(\npreds <- mcmapply(knn.grid,xCor,yCor,\n                  SIMPLIFY = F,\n                  mc.preschedule = F,\n                  mc.cores = getOption(\"mc.cores\", 4L))\n\n)\n\nknn.preds <- ldply(preds, data.frame)\n  knn.preds[,1] <- as.character(knn.preds[,1])\n  knn.preds[,2] <- as.character(knn.preds[,2])\n  knn.preds[,3] <- as.character(knn.preds[,3])\n  colnames(knn.preds) <- c(\"top3\",\"pred_place_id\",\"true_place_id\") #colnames\n  knn.preds[knn.preds == \"NA\"] <- \"\" #replace NA values\n\n#separate predictions for evaluation\nknn.preds %>%\n  separate(top3, c(\"pred1\",\"pred2\",\"pred3\"), \" \") -> knn.preds\n\n#evaluate accuracy in top 3 predictions\nmean(knn.preds[,1] == knn.preds[,5] | knn.preds[,2] == knn.preds[,5] | knn.preds[,3] == knn.preds[,5] )\n\n#evaluate accuracy in first prediction\nmean(knn.preds[,4] == knn.preds[,5])\n\n#timing.\nt2 <- Sys.time()\t\nt2-t1 #finish - start time\n\n```",
    "created" : 1513227832434.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "4082133766",
    "id" : "2E75E251",
    "lastKnownWriteTime" : 1480990897,
    "last_content_update" : 1480990897,
    "path" : "~/Google Drive/Semester Archive/Fall 2016/240C/finalProject/Facebook-Checkin-Predicton/KNN_cam_12052016.Rmd",
    "project_path" : null,
    "properties" : {
    },
    "relative_order" : 10,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_markdown"
}