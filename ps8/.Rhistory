names(results) <-  c("b0", "b1", "sigma2", "ll")
#init parms
missing <- is.na(y)
mod <- lm(y ~ x)
results[1, ] <- c(mod$coefficients, var(mod$residuals), logLik(mod)[[1]])
for(i in 2:stop) {
#E-step: impute censored data
mu <- results$b0[i - 1] + results$b1[i - 1] * x[missing]
tau_star <- (tau - mu) / sqrt(results$sigma2[i - 1])
rho <- dnorm(tau_star) / (1 - pnorm(tau_star))
y[missing] <- mu + sqrt(results$sigma2[i - 1]) * rho
var_z <- results$sigma2[i - 1] * (1 + tau_star * rho-rho^2)
#M-step: re-compute parameters
mod <- lm(y ~ x)
results[i, ] <- c(mod$coefficients,
var(mod$residuals) + sum(var_z) / length(x),
logLik(mod)[[1]])
#evaluate stopping criteria
if(abs(results$ll[i] - results$ll[i - 1]) < stop)
{return(results[1:i,])}
}
return(results)
}
parms_no_missing <- c(mod$coefficients, var(mod$residuals), logLik(mod)[[1]])
names(parms_no_missing) <- c("b0", "b1", "sigma2", "logLik")
tau_80 <- quantile(yComplete, probs = c(0.80))
y_80 <- yComplete
y_80[y_80 > tau_80] <- NA
em_80 <- em(x, y_80, tau_80)
tau_50 <- quantile(yComplete)[3]
y_50 <- yComplete
y_50[y_50 > tau_50] <- NA
em_50 <- em(x, y_50, tau_50)
tau_20 <- quantile(yComplete, probs = c(0.20))
y_20 <- yComplete
y_20[y_20 > tau_20] <- NA
em_20 <- em(x, y_20, tau_20)
est_parm <- rbind(parms_no_missing,
tail(em_80, 1),
tail(em_50, 1),
tail(em_20, 1))
colnames(est_parm) <- c("beta0", "beta1", "sigma2", "logLikelihood")
rownames(est_parm) <- c("No miss", "20% miss", "50% miss", "80% miss")
require(xtable)
tbl=xtable(est_parm,caption="Parameter estimates for different missingness thresholds with user defined function.",comment=F,row.names=T,align="lcccc")
print(tbl,floating=T,include.rownames=T,caption.placement="top",caption.width="35em")
loglikeFunc = function(theta, x, y, tau) {
#theta = c(beta0, beta1, log(sigma2))
#x = x_i values (vector)
#y = y_i values, censored==NA (vector)
#tau = y_i censor threshold
#get parameters and other values for calcs
beta0 <- theta[1]
beta1 <- theta[2]
sigma2 <- exp(theta[3])
missingY <- is.na(y)
mu <- beta0 + beta1 * x
#estimate loglik for y_i
loglik_y <- sum(dnorm(y[!missingY], mean = mu[!missingY],
sd = sqrt(sigma2),
log = T))
#estimate z_i (missingY y_i values)
tau_star <- (tau - mu[missingY]) / sqrt(sigma2)
rho <- dnorm(tau_star) / (1 - pnorm(tau_star))
z <- mu[missingY] + sqrt(sigma2) * rho
var_z <- sigma2 * (1 + tau_star * rho - rho^2)
loglik_z <- sum(log(dtruncnorm(z, a = tau, mean = mu[missingY], sd = sqrt(var_z))))
return((loglik_y + loglik_z))
}
mod_80 <- lm(y_80 ~ x)
mod_80_theta <- c(mod_80$coefficients, log(var(mod_80$residuals)))
optim_80 <- optim(mod_80_theta, fn = loglikeFunc, x = x, y = y_80, tau = tau_80,
control = list(parscale=c(0.1, 1, 1), fnscale = -1),
method="BFGS", hessian = T)
require(truncnorm) #for truncated norm distribution
loglikeFunc = function(theta, x, y, tau) {
#theta = c(beta0, beta1, log(sigma2))
#x = x_i values (vector)
#y = y_i values, censored==NA (vector)
#tau = y_i censor threshold
#get parameters and other values for calcs
beta0 <- theta[1]
beta1 <- theta[2]
sigma2 <- exp(theta[3])
missingY <- is.na(y)
mu <- beta0 + beta1 * x
#estimate loglik for y_i
loglik_y <- sum(dnorm(y[!missingY], mean = mu[!missingY],
sd = sqrt(sigma2),
log = T))
#estimate z_i (missingY y_i values)
tau_star <- (tau - mu[missingY]) / sqrt(sigma2)
rho <- dnorm(tau_star) / (1 - pnorm(tau_star))
z <- mu[missingY] + sqrt(sigma2) * rho
var_z <- sigma2 * (1 + tau_star * rho - rho^2)
loglik_z <- sum(log(dtruncnorm(z, a = tau, mean = mu[missingY], sd = sqrt(var_z))))
return((loglik_y + loglik_z))
}
mod_80 <- lm(y_80 ~ x)
mod_80_theta <- c(mod_80$coefficients, log(var(mod_80$residuals)))
optim_80 <- optim(mod_80_theta, fn = loglikeFunc, x = x, y = y_80, tau = tau_80,
control = list(parscale=c(0.1, 1, 1), fnscale = -1),
method="BFGS", hessian = T)
mod_20 <- lm(y_20 ~ x)
mod_20_theta  <- c(mod_20$coefficients, log(var(mod_20$residuals)))
optim_20 <- optim(mod_20_theta, fn = loglikeFunc, x = x, y = y_20, tau = tau_20,
control = list(parscale=c(0.1, 1, 1), fnscale = -1),
method="BFGS", hessian = T)
res_optim <- rbind("No miss" = parms_no_missing,
"20% miss" = c(optim_80$par, optim_80$value),
"80% miss" = c(optim_20$par, optim_20$value))
res_optim
require(xtable)
tbl=xtable(res_optim,caption="Parameter estimates for different missingness thresholds with optim().",comment=F,row.names=T,align="lcccc")
print(tbl,floating=T,include.rownames=T,caption.placement="top",caption.width="35em")
res_optim <- rbind("No miss" = parms_no_missing,
"20% miss" = c(optim_80$par, optim_80$value),
"80% miss" = c(optim_20$par, optim_20$value))
res_optim
res_userFun <- rbind(parms_no_missing,
tail(em_80, 1),
tail(em_50, 1),
tail(em_20, 1))
paste0("Parameter estimates for different missingness ",
"thresholds with user defined function.")
loglikeFunc = function(theta, x, y, tau) {
#theta = c(beta0, beta1, log(sigma2))
#x = x_i values (vector)
#y = y_i values, censored==NA (vector)
#tau = y_i censor threshold
#b0 = beta0
#b1 = beta1
#sigma2 = sigma^2
#missingY = missing values of Y (Z)
#mu = estimate of Y (or Z) given coef, beta's and cov, x
#get parameters and other values for calcs
b0 <- theta[1]
b1 <- theta[2]
sigma2 <- exp(theta[3])
missingY <- is.na(y)
mu <- b0 + b1 * x
#estimate loglik for y_i
loglike_y <- sum(dnorm(y[!missingY], mean = mu[!missingY],
sd = sqrt(sigma2),
log = T))
#estimate z_i (missingY y_i values)
tau_star <- (tau - mu[missingY]) / sqrt(sigma2)
rho <- dnorm(tau_star) / (1 - pnorm(tau_star))
z <- mu[missingY] + sqrt(sigma2) * rho
var_z <- sigma2 * (1 + tau_star * rho - rho^2)
loglike_z <- sum(log(dtruncnorm(z, a = tau, mean = mu[missingY], sd = sqrt(var_z))))
return((loglike_y + loglike_z))
}
mod_80 <- lm(y_80 ~ x)
mod_80_theta <- c(mod_80$coefficients, log(var(mod_80$residuals)))
optim_80 <- optim(mod_80_theta, fn = loglikeFunc, x = x, y = y_80, tau = tau_80,
control = list(parscale=c(0.1, 1, 1), fnscale = -1),
method="BFGS", hessian = T)
mod_20 <- lm(y_20 ~ x)
mod_20_theta  <- c(mod_20$coefficients, log(var(mod_20$residuals)))
optim_20 <- optim(mod_20_theta, fn = loglikeFunc, x = x, y = y_20, tau = tau_20,
control = list(parscale=c(0.1, 1, 1), fnscale = -1),
method="BFGS", hessian = T)
res_optim <- rbind("No miss" = parms_no_missing,
"20% miss" = c(optim_80$par, optim_80$value),
"80% miss" = c(optim_20$par, optim_20$value))
res_optim
optim_20
res_optim <- rbind("No miss" = parms_no_missing,
"20% miss" = c(optim_80$par, optim_80$value, optim_80$counts),
"80% miss" = c(optim_20$par, optim_20$value, optim_20$counts))
res_optim <- rbind("No miss" = c(parms_no_missing, "-", "-"),
"20% miss" = c(optim_80$par, optim_80$value, optim_80$counts),
"80% miss" = c(optim_20$par, optim_20$value, optim_20$counts))
res_optim
colnames(res_optim)
colnames(res_optim) <- c("beta_0", "beta_1", "sigma^2",
"loglike", "count.function", "count.gradient")
res_userFun <- rbind(parms_no_missing,
tail(em_80, 1),
tail(em_50, 1),
tail(em_20, 1))
em_80
em_50
tail(em_80, 1)
tau_80 <- quantile(yComplete, probs = c(0.80))
y_80 <- yComplete
y_80[y_80 > tau_80] <- NA
em_80 <- em(x, y_80, tau_80)
em_80
em = function(x, y, tau, stop=1000, stopLike=1e-6) { # x: vector of x_i values
#y = vector of y_i values, with NA for censored data
#x = observted covariates
#b0 = beta0
#b1 = beta1
#sigma2 = sigma^2
#ll = log Likelihood
#tau: threshold for y_i censoring
#stop: maximum number of iterations through EM algorithm
#stopLike: diff of loglik of parameters of iterations
#returns: data frame of (b_0, b_1, s^2, loglik) for each iteration
#set output df
results <- data.frame(matrix(NA, nrow=stop, ncol = 4))
names(results) <-  c("b0", "b1", "sigma2", "ll")
#init parms
missing <- is.na(y)
mod <- lm(y ~ x)
results[1, ] <- c(mod$coefficients, var(mod$residuals), logLik(mod)[[1]])
for(i in 2:stop) {
#E-step: impute censored data
mu <- results$b0[i - 1] + results$b1[i - 1] * x[missing]
tau_star <- (tau - mu) / sqrt(results$sigma2[i - 1])
rho <- dnorm(tau_star) / (1 - pnorm(tau_star))
y[missing] <- mu + sqrt(results$sigma2[i - 1]) * rho
var_z <- results$sigma2[i - 1] * (1 + tau_star * rho-rho^2)
#M-step: re-compute parameters
mod <- lm(y ~ x)
results[i, ] <- c(mod$coefficients,
var(mod$residuals) + sum(var_z) / length(x),
logLik(mod)[[1]])
#evaluate stopping criteria
#if(abs(results$ll[i] - results$ll[i - 1]) < stop)
#{return(results[1:i, ])}
}
return(results)
}
parms_no_missing <- c(mod$coefficients, var(mod$residuals), logLik(mod)[[1]])
names(parms_no_missing) <- c("b0", "b1", "sigma2", "logLik")
tau_80 <- quantile(yComplete, probs = c(0.80))
y_80 <- yComplete
y_80[y_80 > tau_80] <- NA
em_80 <- em(x, y_80, tau_80)
em_80
em = function(x, y, tau, stop=1000, stopLike=1e-6) { # x: vector of x_i values
#y = vector of y_i values, with NA for censored data
#x = observted covariates
#b0 = beta0
#b1 = beta1
#sigma2 = sigma^2
#ll = log Likelihood
#tau: threshold for y_i censoring
#stop: maximum number of iterations through EM algorithm
#stopLike: diff of loglik of parameters of iterations
#returns: data frame of (b_0, b_1, s^2, loglik) for each iteration
#set output df
results <- data.frame(matrix(NA, nrow=stop, ncol = 4))
names(results) <-  c("b0", "b1", "sigma2", "ll")
#init parms
missing <- is.na(y)
mod <- lm(y ~ x)
results[1, ] <- c(mod$coefficients, var(mod$residuals), logLik(mod)[[1]])
for(i in 2:stop) {
#E-step: impute censored data
mu <- results$b0[i - 1] + results$b1[i - 1] * x[missing]
tau_star <- (tau - mu) / sqrt(results$sigma2[i - 1])
rho <- dnorm(tau_star) / (1 - pnorm(tau_star))
y[missing] <- mu + sqrt(results$sigma2[i - 1]) * rho
var_z <- results$sigma2[i - 1] * (1 + tau_star * rho-rho^2)
#M-step: re-compute parameters
mod <- lm(y ~ x)
results[i, ] <- c(mod$coefficients,
var(mod$residuals) + sum(var_z) / length(x),
logLik(mod)[[1]])
#evaluate stopping criteria
if(abs(results$ll[i] - results$ll[i - 1]) == 0) {
return(results[1:i, ])
}
}
return(results)
}
parms_no_missing <- c(mod$coefficients, var(mod$residuals), logLik(mod)[[1]])
names(parms_no_missing) <- c("b0", "b1", "sigma2", "logLik")
tau_80 <- quantile(yComplete, probs = c(0.80))
y_80 <- yComplete
y_80[y_80 > tau_80] <- NA
em_80 <- em(x, y_80, tau_80)
em_80
em = function(x, y, tau, stop=1000, stopLike=1e-6) { # x: vector of x_i values
#y = vector of y_i values, with NA for censored data
#x = observted covariates
#b0 = beta0
#b1 = beta1
#sigma2 = sigma^2
#ll = log Likelihood
#tau: threshold for y_i censoring
#stop: maximum number of iterations through EM algorithm
#stopLike: diff of loglik of parameters of iterations
#returns: data frame of (b_0, b_1, s^2, loglik) for each iteration
#set output df
results <- data.frame(matrix(NA, nrow=stop, ncol = 4))
names(results) <-  c("b0", "b1", "sigma2", "ll")
#init parms
missing <- is.na(y)
mod <- lm(y ~ x)
results[1, ] <- c(mod$coefficients, var(mod$residuals), logLik(mod)[[1]])
for(i in 2:stop) {
#E-step: impute censored data
mu <- results$b0[i - 1] + results$b1[i - 1] * x[missing]
tau_star <- (tau - mu) / sqrt(results$sigma2[i - 1])
rho <- dnorm(tau_star) / (1 - pnorm(tau_star))
y[missing] <- mu + sqrt(results$sigma2[i - 1]) * rho
var_z <- results$sigma2[i - 1] * (1 + tau_star * rho-rho^2)
#M-step: re-compute parameters
mod <- lm(y ~ x)
results[i, ] <- c(mod$coefficients,
var(mod$residuals) + sum(var_z) / length(x),
logLik(mod)[[1]])
#evaluate stopping criteria
if(abs(results$ll[i] - results$ll[i - 1]) < sqrt(.Machine$double.eps)) {
return(results[1:i, ])
}
}
return(results)
}
parms_no_missing <- c(mod$coefficients, var(mod$residuals), logLik(mod)[[1]])
names(parms_no_missing) <- c("b0", "b1", "sigma2", "logLik")
tau_80 <- quantile(yComplete, probs = c(0.80))
y_80 <- yComplete
y_80[y_80 > tau_80] <- NA
em_80 <- em(x, y_80, tau_80)
em_80
rm(list=ls())
source("./ps8.R")
em = function(x, y, tau, stop=1000, stopLike=1e-6) { # x: vector of x_i values
#y = vector of y_i values, with NA for censored data
#x = observted covariates
#b0 = beta0
#b1 = beta1
#sigma2 = sigma^2
#ll = log Likelihood
#tau: threshold for y_i censoring
#stop: maximum number of iterations through EM algorithm
#stopLike: diff of loglik of parameters of iterations
#returns: data frame of (b_0, b_1, s^2, loglik) for each iteration
#set output df
results <- data.frame(matrix(NA, nrow=stop, ncol = 4))
names(results) <-  c("b0", "b1", "sigma2", "ll")
#init parms
missing <- is.na(y)
mod <- lm(y ~ x)
results[1, ] <- c(mod$coefficients, var(mod$residuals), logLik(mod)[[1]])
for(i in 2:stop) {
#E-step: impute censored data
mu <- results$b0[i - 1] + results$b1[i - 1] * x[missing]
tau_star <- (tau - mu) / sqrt(results$sigma2[i - 1])
rho <- dnorm(tau_star) / (1 - pnorm(tau_star))
y[missing] <- mu + sqrt(results$sigma2[i - 1]) * rho
var_z <- results$sigma2[i - 1] * (1 + tau_star * rho-rho^2)
#M-step: re-compute parameters
mod <- lm(y ~ x)
results[i, ] <- c(mod$coefficients,
var(mod$residuals) + sum(var_z) / length(x),
logLik(mod)[[1]])
#evaluate stopping criteria (diff in ll between iter < sqrt machine eps)
if(abs(results$ll[i] - results$ll[i - 1]) < sqrt(.Machine$double.eps)) {
return(results[1:i, ])
}
}
return(results)
}
parms_no_missing <- c(mod$coefficients, var(mod$residuals), logLik(mod)[[1]])
names(parms_no_missing) <- c("b0", "b1", "sigma2", "logLik")
tau_80 <- quantile(yComplete, probs = c(0.80))
y_80 <- yComplete
y_80[y_80 > tau_80] <- NA
em_80 <- em(x, y_80, tau_80)
tau_50 <- quantile(yComplete)[3]
y_50 <- yComplete
y_50[y_50 > tau_50] <- NA
em_50 <- em(x, y_50, tau_50)
tau_20 <- quantile(yComplete, probs = c(0.20))
y_20 <- yComplete
y_20[y_20 > tau_20] <- NA
em_20 <- em(x, y_20, tau_20)
parms_no_missing
nrow(em_80)
res_userFun <- rbind(c(parms_no_missing, "-"),
c(tail(em_80, 1), nrow(em_80)),
c(tail(em_50, 1), nrow(em_50))
c(tail(em_20, 1), nrow(em_20)))
res_userFun <- rbind(c(parms_no_missing, "-"),
c(tail(em_80, 1), nrow(em_80)),
c(tail(em_50, 1), nrow(em_50)),
c(tail(em_20, 1), nrow(em_20)))
res_userFun
colnames(res_userFun) <- c("beta0", "beta1", "sigma2", "logLikelihood", "conv_iter")
rownames(res_userFun) <- c("No miss", "20% miss", "50% miss", "80% miss")
res_userFun <- rbind(c(parms_no_missing, "-"),
c(tail(em_80, 1), nrow(em_80)),
c(tail(em_50, 1), nrow(em_50)),
c(tail(em_20, 1), nrow(em_20)))
colnames(res_userFun) <- c("beta0", "beta1", "sigma2", "logLikelihood", "conv_iterations")
rownames(res_userFun) <- c("No miss", "20% miss", "50% miss", "80% miss")
require(xtable)
tbl <- xtable(res_userFun,
caption=paste0("Parameter estimates for different missingness ",
"thresholds with user defined function."),
comment=F,row.names=T,align="lccccc")
print(tbl, floating = T, include.rownames = T,
caption.placement="top",caption.width="35em")
rm(list=ls())
require(knitr)
setwd("/Users/CamAdams/repos/STAT243/ps8/")
knit2pdf(input = "ps8.Rnw", output = "ps8.tex")
print(tbl, floating = T, include.rownames = T,
caption.placement="top",caption.width="35em", digits = 2)
res_userFun
rm(list=ls())
require(knitr)
setwd("/Users/CamAdams/repos/STAT243/ps8/")
knit2pdf(input = "ps8.Rnw", output = "ps8.tex")
rm(list= ls())
source("./ps8.R")
em = function(x, y, tau, stop=1000, stopLike=1e-6) { # x: vector of x_i values
#y = vector of y_i values, with NA for censored data
#x = observted covariates
#b0 = beta0
#b1 = beta1
#sigma2 = sigma^2
#ll = log Likelihood
#tau: threshold for y_i censoring
#stop: maximum number of iterations through EM algorithm
#stopLike: diff of loglik of parameters of iterations
#returns: data frame of (b_0, b_1, s^2, loglik) for each iteration
#set output df
results <- data.frame(matrix(NA, nrow=stop, ncol = 4))
names(results) <-  c("b0", "b1", "sigma2", "ll")
#init parms
missing <- is.na(y)
mod <- lm(y ~ x)
results[1, ] <- c(mod$coefficients, var(mod$residuals), logLik(mod)[[1]])
for(i in 2:stop) {
#E-step: impute censored data
mu <- results$b0[i - 1] + results$b1[i - 1] * x[missing]
tau_star <- (tau - mu) / sqrt(results$sigma2[i - 1])
rho <- dnorm(tau_star) / (1 - pnorm(tau_star))
y[missing] <- mu + sqrt(results$sigma2[i - 1]) * rho
var_z <- results$sigma2[i - 1] * (1 + tau_star * rho-rho^2)
#M-step: re-compute parameters
mod <- lm(y ~ x)
results[i, ] <- c(mod$coefficients,
var(mod$residuals) + sum(var_z) / length(x),
logLik(mod)[[1]])
#evaluate stopping criteria (diff in ll between iter < sqrt machine eps)
if(abs(results$ll[i] - results$ll[i - 1]) < sqrt(.Machine$double.eps)) {
return(results[1:i, ])
}
}
return(results)
}
parms_no_missing <- c(mod$coefficients, var(mod$residuals), logLik(mod)[[1]])
names(parms_no_missing) <- c("b0", "b1", "sigma2", "logLik")
tau_80 <- quantile(yComplete, probs = c(0.80))
y_80 <- yComplete
y_80[y_80 > tau_80] <- NA
em_80 <- em(x, y_80, tau_80)
tau_50 <- quantile(yComplete)[3]
y_50 <- yComplete
y_50[y_50 > tau_50] <- NA
em_50 <- em(x, y_50, tau_50)
tau_20 <- quantile(yComplete, probs = c(0.20))
y_20 <- yComplete
y_20[y_20 > tau_20] <- NA
em_20 <- em(x, y_20, tau_20)
res_userFun <- rbind(c(parms_no_missing, 0),
c(tail(em_80, 1), nrow(em_80)),
c(tail(em_50, 1), nrow(em_50)),
c(tail(em_20, 1), nrow(em_20)))
res_userFun
colnames(res_userFun) <- c("beta0", "beta1", "sigma2", "logLikelihood", "conv_iterations")
rownames(res_userFun) <- c("No miss", "20% miss", "50% miss", "80% miss")
res_userFun
tbl <- xtable(res_userFun,
caption=paste0("Parameter estimates for different missingness ",
"thresholds with user defined function."),
comment=F,row.names=T,align="lccccc")
print(tbl, floating = T, include.rownames = T,
caption.placement="top",caption.width="35em", digits = 2)
nrow(em_80)
rm(list=ls())
require(knitr)
setwd("/Users/CamAdams/repos/STAT243/ps8/")
knit2pdf(input = "ps8.Rnw", output = "ps8.tex")
rm(list=ls())
require(knitr)
setwd("/Users/CamAdams/repos/STAT243/ps8/")
knit2pdf(input = "ps8.Rnw", output = "ps8.tex")
rm(list=ls())
require(knitr)
setwd("/Users/CamAdams/repos/STAT243/ps8/")
knit2pdf(input = "ps8.Rnw", output = "ps8.tex")
rm(list=ls())
require(knitr)
setwd("/Users/CamAdams/repos/STAT243/ps8/")
knit2pdf(input = "ps8.Rnw", output = "ps8.tex")
source("./ps8.R")
x1 <- x2 <- seq(-10, 10, length.out = n)
x <- cbind(expand.grid(x1, x2), 0)
x <- cbind(expand.grid(x1, x2), 0)
x3_0    <- matrix(apply(cbind(expand.grid(x1, x2), 0), 1, f), ncol = n)
x3_5    <- matrix(apply(cbind(expand.grid(x1, x2), 5), 1, f), ncol = n)
x3_neg5 <- matrix(apply(cbind(expand.grid(x1, x2), -5), 1, f), ncol = n)
x3_10   <- matrix(apply(cbind(expand.grid(x1, x2), 10), 1, f), ncol = n)
par(mfrow = c(2, 2))
contour(x1, x2, x3_0, main = "x3 = 0", asp = 1)
contour(x1, x2, x3_5, main = "x3 = 5", asp = 1)
contour(x1, x2, x3_neg5, main = "x3 = -5", asp = 1)
contour(x1, x2, x3_10, main = "x3 = 10", asp = 1)
rm(list=ls())
require(knitr)
setwd("/Users/CamAdams/repos/STAT243/ps8/")
knit2pdf(input = "ps8.Rnw", output = "ps8.tex")
